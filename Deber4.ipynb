{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework 4**\n",
        "\n",
        "- **Authors:** Anahí Andrade (00323313), Mateo Salgado (00324999)\n",
        "\n",
        "- **Course:** CMP 5006 - Information Security (NRC: 3715)\n",
        "\n",
        "- **Institution:** Universidad San Francisco de Quito"
      ],
      "metadata": {
        "id": "3Ix8S-FCWsEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **1. Foundational Research: Ecuadorian Data Sovereignty (LOPDP)**\n",
        "\n",
        "Ecuador's **Ley Orgánica de Protección de Datos Personales (LOPDP)**, enforced starting in July 2023, establishes comprehensive individual rights over personal data. This module requires you to research the specific mandates of this law as they relate to **automated decision-making** and **cross-border data management**.\n",
        "\n",
        "* **What are the three core principles (criterios mínimos) that govern all data processing activities under the LOPDP?**\n",
        "\n",
        "* **Locate the specific article (or section within an article) of the LOPDP that grants the data subject the right \"to not be object of a decision based solely on automated valuations\".** Explain the details and protections it provides.\n",
        "\n",
        "* **In the context of an AI-driven system (e.g., hiring or loan approval), explain the operational impact of this right.** How does this LOPDP provision compel a data controller to provide human intervention or oversight?\n",
        "\n",
        "* **Under what conditions is the international transfer of personal data restricted by the LOPDP?**\n",
        "\n",
        "* **Explain the role of the Data Protection Authority (DPA) regarding international data transfers.** How does this requirement create operational friction or regulatory compliance barriers for a multinational AI company that typically relies on centralized cloud infrastructure outside of Ecuador?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "NSZJHSTfWt33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Solución:**\n",
        "\n",
        "\n",
        "## **Principios rectores (criterios mínimos) según el Artículo 10 de la LOPDP:**\n",
        "\n",
        "La Ley Orgánica de Protección de Datos Personales (LOPDP) establece un marco riguroso para el tratamiento de la información personal basado en trece principios rectores contemplados en el Artículo 10. Sin embargo, el Artículo 2, (inciso e), y el Artículo 11 de la ley especifican que existen tres criterios mínimos fundamentales que deben cumplirse incluso en tratamientos regulados por normativa especializada (gestión de riesgos, desastres naturales, seguridad nacional): legalidad, proporcionalidad y necesidad.\n",
        "\n",
        "- **Legalidad (Juridicidad - Art. 10.a):** Los datos personales deben tratarse con estricto apego y cumplimiento a los principios, derechos y obligaciones establecidas en la Constitución, los instrumentos internacionales, la LOPDP, su Reglamento y la demás normativa aplicable. Todo tratamiento requiere una base jurídica válida conforme al Artículo 7.\n",
        "\n",
        "- **Proporcionalidad (Art. 10.f):** El tratamiento debe ser adecuado, necesario, oportuno, relevante y no excesivo con relación a las finalidades para las cuales hayan sido recogidos los datos o a la naturaleza misma de las categorías especiales de datos. Esto significa que el volumen y tipo de datos procesados debe ser estrictamente proporcional al objetivo legítimo perseguido.\n",
        "\n",
        "- **Necesidad (implícito en Art. 10.e - Pertinencia y minimización):** Los datos personales deben ser pertinentes y estar limitados a lo estrictamente necesario para el cumplimiento de la finalidad del tratamiento. Este principio obliga a los responsables a recopilar únicamente la información indispensable, evitando el tratamiento excesivo o irrelevante.\n",
        "\n",
        "Estos tres criterios constituyen el estándar mínimo obligatorio que debe observarse en todo tratamiento de datos personales en Ecuador, incluso cuando existe normativa especializada sectorial, garantizando así un nivel base de protección de los derechos fundamentales de los titulares.\n",
        "\n",
        "## **El derecho a la no decisión automatizada y la intervención humana:**\n",
        "\n",
        "En cuanto a la protección frente a sistemas de inteligencia artificial y valoración algorítmica, el **Artículo 20 de la LOPDP** consagra el derecho del titular a **no ser objeto de una decisión basada única o parcialmente en valoraciones automatizadas**. Este artículo es crucial, ya que faculta al ciudadano a solicitar una explicación motivada sobre la decisión tomada, presentar sus observaciones, impugnar la valoración y, lo más importante, **exigir la intervención humana**. Este derecho asegura que la lógica algorítmica no vulnere derechos fundamentales ni genere discriminación injustificada.\n",
        "\n",
        "## **Impacto operacional de la intervención humana:**\n",
        "\n",
        "En el contexto operativo de un sistema de IA utilizado para aplicaciones críticas, como la contratación de personal o la aprobación de créditos, esta disposición legal obliga al responsable del tratamiento a diseñar flujos de trabajo **\"human-in-the-loop\"**. Esto significa que, por ejemplo, un algoritmo no puede rechazar automáticamente una solicitud de préstamo sin que un analista humano revise la decisión y valide los criterios utilizados. De esta manera, se garantiza que la decisión final, aunque asistida por IA, cumpla con el principio de proporcionalidad y se mantenga dentro del marco de la ley.\n",
        "\n",
        "## **Gestión de datos transfronterizos: Restricciones, Garantías y Excepciones:**\n",
        "\n",
        "La transferencia internacional de datos personales bajo la LOPDP está estrictamente regulada en el Capítulo IX (Artículos 55-61) para prevenir que la información salga del país hacia jurisdicciones que no ofrezcan garantías de protección equivalentes. El marco normativo establece tres niveles de regulación:\n",
        "\n",
        "**1. Transferencias a países con nivel adecuado de protección (Artículo 56):**\n",
        "\n",
        "Las transferencias internacionales son permitidas cuando el país, organización o territorio destino ha sido declarado por la Autoridad de Protección de Datos Personales (ANPD) como de \"nivel adecuado de protección\". Esta declaración se emite mediante resolución motivada y verifica que la jurisdicción receptora cumple con estándares reconocidos internacionalmente conforme a criterios establecidos en el Reglamento de la ley. La ANPD mantiene una lista pública actualizada de países y organizaciones con esta declaración.\n",
        "\n",
        "**2. Transferencias mediante garantías adecuadas (Artículo 57):**\n",
        "\n",
        "Cuando el país destino NO tiene declaración de nivel adecuado, la transferencia aún puede realizarse si el responsable o encargado del tratamiento ofrece garantías adecuadas mediante instrumentos jurídicos vinculantes que contemplen:\n",
        "- Cumplimiento de principios, derechos y obligaciones de la LOPDP en estándar igual o mayor.\n",
        "- Efectiva tutela del derecho a la protección de datos mediante acciones administrativas o judiciales disponibles.\n",
        "- Derecho a solicitar reparación integral en caso de violaciones.\n",
        "\n",
        "Estas garantías pueden implementarse a través de:\n",
        "- Cláusulas contractuales tipo.\n",
        "- Normas corporativas vinculantes (Artículo 58) - requieren aprobación previa de la ANPD.\n",
        "- Otros mecanismos que garanticen el mismo nivel de protección.\n",
        "\n",
        "**3. Excepciones que levantan las restricciones (Artículo 60):**\n",
        "\n",
        "Las transferencias internacionales pueden realizarse SIN nivel adecuado de protección ni garantías adicionales en los siguientes casos excepcionales:\n",
        "\n",
        "- **Consentimiento explícito del titular** tras haber sido informado de los posibles riesgos de la transferencia.\n",
        "- **Cumplimiento de obligación legal o regulatoria** aplicable al responsable\n",
        "- **Ejecución de un contrato** entre el titular y el responsable, o medidas precontractuales solicitadas por el titular.\n",
        "- **Razones de interés público** debidamente justificadas\n",
        "- **Colaboración judicial internacional** o cooperación en investigación de infracciones.\n",
        "- **Cumplimiento de compromisos** adquiridos en procesos de cooperación internacional entre Estados.\n",
        "- **Operaciones bancarias y bursátiles** reguladas.\n",
        "- **Formulación, ejercicio o defensa de reclamaciones** administrativas o jurisdiccionales.\n",
        "- **Protección de intereses vitales** del titular cuando esté física o jurídicamente incapacitado para dar consentimiento.\n",
        "- **Requerimientos para cumplimiento de competencias institucionales** de conformidad con la normativa aplicable.\n",
        "\n",
        "## **Fricción operacional para multinacionales de IA:**\n",
        "\n",
        "El sistema de la LOPDP opera bajo un principio de **restricción por defecto**: Toda transferencia internacional está prohibida salvo que cumpla con uno de los tres mecanismos descritos anteriormente. Esto crea significativa fricción operacional porque:\n",
        "- Las empresas NO pueden asumir libre transferencia internacional sin verificación previa.\n",
        "- Se requiere documentación formal (contratos, declaraciones, autorizaciones) antes de cada transferencia.\n",
        "- Debe registrarse toda transferencia internacional en el Registro Nacional de Protección de Datos Personales (Artículo 59).\n",
        "- La ANPD puede implementar controles ex post y requerir auditorías de cumplimiento (Artículo 56).\n",
        "- Existe obligación de control continuo (Artículo 61): Si un país pierde el nivel adecuado, las transferencias deben cesar inmediatamente.\n",
        "\n",
        "Desde este punto, para una empresa multinacional de IA que típicamente utiliza infraestructura de nube centralizada fuera de Ecuador (como en EE. UU.), este requisito crea una **fricción operativa y significativas barreras de cumplimiento**. La empresa no puede simplemente replicar datos de usuarios ecuatorianos a sus servidores globales. Al contrario, deben segmentar legalmente el flujo de datos, firmar contratos complejos de transferencia o, como último recurso, localizar servidores en Ecuador. Esto tiene el impacto directo de **incrementar los costos y la latencia técnica**, desafiando el modelo de eficiencia que se logra con una nube global unificada."
      ],
      "metadata": {
        "id": "dwq45uP2XfOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **2. Corporate Policy Scrutiny: The Data Repurposing Conflict**\n",
        "\n",
        "Major generative AI companies frequently face scrutiny for collecting and repurposing user data (such as chat inputs) for model training, a practice that directly challenges the principles of purpose limitation and explicit consent in global privacy laws.\n",
        "\n",
        "* **Select two major generative AI providers** (e.g., OpenAI, Meta, or Anthropic). **Briefly summarize how each company differentiates the data usage practices** between their **Enterprise/API Services** (for paying business clients) and their **Consumer/Chatbot Services** (for free public users) regarding model training.\n",
        "\n",
        "* **Analyze the public-facing policy for the consumer chat version of one of your selected companies.** **Identify the type of user input data** (e.g., chat content, account info, technical data) that may be used for model training.\n",
        "\n",
        "* **Describe the practical process a user must follow to opt out** of having their data used for training (e.g., submission of a form, navigation of settings, or use of a specific toggle).\n",
        "\n",
        "* **Critically evaluate: How does this opt-out mechanism conflict with the LOPDP's mandate for prior, informed, and explicit consent for data processing?**\n",
        "\n",
        "* **Legal Risk Scenarios:** **Research a recent legal challenge or public controversy** where an AI company (e.g., Meta, LinkedIn, or an AI company) was accused of using previously collected user-generated content or biometric data for a new, secondary AI training purpose without proper consent. **Briefly summarize the nature of the alleged violation** (e.g., biometric privacy, repurposing of communication data).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "NKC19efRXrV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Solución:**\n",
        "\n",
        "## **Diferenciación de prácticas de uso de datos (OpenAI y Anthropic):**\n",
        "\n",
        "Las principales empresas de IA generativa, como OpenAI y Anthropic, establecen una diferenciación crítica en el manejo de datos de usuario para el entrenamiento de modelos, distinguiendo claramente entre servicios empresariales y de consumo.\n",
        "\n",
        "**OpenAI - Política de datos:**\n",
        "\n",
        "En sus servicios empresariales (ChatGPT Enterprise, ChatGPT Business, API Platform), OpenAI aplica por defecto una política estricta de Zero Data Retention donde los datos no son utilizados para entrenar modelos. Según su Enterprise Privacy Policy actualizada en 2024, \"By default, we do not use your business data for training our models\". Los clientes empresariales tienen control total sobre sus datos, con opciones de retención personalizables (incluyendo política de cero retención) y cifrado AES-256 en reposo y TLS 1.2+ en tránsito.\n",
        "\n",
        "Por el contrario, en sus versiones de consumo (ChatGPT Free, ChatGPT Plus), la configuración predeterminada permite el uso de las conversaciones del usuario para entrenar y refinar los modelos. Sin embargo, OpenAI implementó en marzo de 2023 un sistema de opt-out donde los usuarios pueden desactivar el entrenamiento mediante la configuración \"Data Controls\" > \"Improve the model for everyone\" en sus ajustes de cuenta.\n",
        "\n",
        "**Anthropic - Política de datos:**\n",
        "\n",
        "Anthropic sigue un modelo similar pero con actualizaciones recientes significativas. En sus **servicios comerciales (Claude for Work - Team/Enterprise, Claude API, implementaciones en AWS Bedrock y Google Vertex AI), Anthropic** no utiliza datos empresariales para entrenamiento por defecto. La retención de logs API fue reducida de 30 a **7 días** a partir del 15 de septiembre de 2025. Los clientes empresariales ahora pueden solicitar acuerdos de **Zero Data Retention (ZDR)** donde los datos se eliminan inmediatamente después de verificaciones de abuso.\n",
        "\n",
        "Para cuentas de consumo (Claude Free, Pro, Max), Anthropic actualizó su política en agosto de 2025 implementando un sistema de opt-in. A diferencia de OpenAI, los usuarios deben **elegir activamente** permitir que sus conversaciones se usen para entrenamiento. Los usuarios que optan por compartir sus datos tienen una retención extendida de hasta 5 años (versus 30 días para quienes no optan). La nueva política entró en vigor el 28 de septiembre de 2025, y los usuarios que no elijan una opción no pueden continuar usando el servicio.\n",
        "\n",
        "Como se puede ver en estos dos casos, esta distinción es fundamental para proteger la privacidad de datos sensibles de negocio en entornos empresariales, mientras se optimiza la calidad de los modelos de consumo mediante datos voluntariamente compartidos con consentimiento explícito.\n",
        "\n",
        "## **Identificación del tipo de datos de usuario utilizados (OpenAI):**\n",
        "\n",
        "Al analizar la política de acceso público para la versión de consumo de OpenAI (ChatGPT gratuito), se identifica que la empresa utiliza varios tipos de inputs para el entrenamiento de sus modelos. El tipo de datos de usuario que puede ser utilizado incluye principalmente el contenido de las conversaciones (es decir, los *prompts* o entradas de texto que el usuario envía al *chatbot*). Además del texto de *chat*, la compañía utiliza los archivos cargados por el usuario durante las interacciones y la retroalimentación que el usuario proporciona sobre las respuestas generadas. Estos datos son considerados esenciales para el proceso de machine learning y ajuste fino, ya que permiten a la IA mejorar su precisión y capacidad de respuesta futura.\n",
        "\n",
        "## **Proceso práctico para la exclusión voluntaria (*Opt-Out*):**\n",
        "\n",
        "El proceso práctico que un usuario debe seguir para ejercer la exclusión voluntaria (*opt-out*) del uso de sus datos para el entrenamiento de modelos es un mecanismo que requiere navegación y acción manual. Para inhabilitar esta función, el usuario debe acceder al menú de \"Configuración\" dentro de la interfaz del *chatbot* o la aplicación correspondiente. Dentro de esa sección, debe buscar la opción \"Controles de datos\" y, finalmente, desactivar manualmente el interruptor que está etiquetado como \"Mejorar el modelo para todos\". Este método sitúa la responsabilidad de la privacidad en el usuario, obligándolo a realizar varios pasos proactivos para impedir el uso de su información.\n",
        "\n",
        "## **Conflicto del mecanismo *Opt-Out* con el mandato de la LOPDP:**\n",
        "\n",
        "El mecanismo de exclusión voluntaria (*opt-out*) implementado por estas empresas entra en conflicto directo con el mandato de la LOPDP ecuatoriana, específicamente con el **Artículo 8**, que exige un consentimiento previo, informado, libre y explícito (*opt-in*). La LOPDP establece que el consentimiento no se puede asumir por defecto, mientras que la práctica corporativa lo asume e impone la carga de la privacidad en el usuario. Esta práctica viola el principio de privacidad por diseño y por defecto, ya que obliga al titular a realizar una acción activa para proteger su información. La ley ecuatoriana demanda que la aprobación del usuario debe darse de manera inequívoca antes de que sus datos sean procesados para cualquier fin de entrenamiento secundario.\n",
        "\n",
        "## **Escenarios de riesgo legal: Controversia de Meta en Brasil:**\n",
        "\n",
        "Un escenario de riesgo legal reciente que ilustra la controversia de la reutilización de datos sin el consentimiento explícito y adecuado es el caso de Meta en Brasil. En julio de 2024, la Autoridad Nacional de Protección de Datos (ANPD) de Brasil ordenó a Meta suspender el uso de datos de usuarios (incluyendo publicaciones, fotos y pies de foto de Facebook e Instagram) para entrenar sus modelos de IA. La ANPD determinó que la naturaleza de la violación residía en que Meta intentó justificar este procesamiento secundario bajo la base legal de \"interés legítimo\" en lugar de obtener el consentimiento explícito y separado de los titulares. La autoridad consideró que la complejidad del proceso de exclusión y la falta de un *opt-in* inicial creaban un riesgo inminente de daño grave a los derechos fundamentales de los usuarios."
      ],
      "metadata": {
        "id": "ChxEzsr2Ycgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **3. Technical Risk Assessment and Mitigation**\n",
        "\n",
        "AI systems, especially those processing sensitive data, require robust security and governance to prevent privacy harms and data access risks. This module focuses on threat modeling and risk management.\n",
        "\n",
        "* **Choose one high-risk application and detail a specific scenario** where it could lead to severe harm or unauthorized data access.\n",
        "\n",
        "* **Assume we deploy a new AI-driven predictive policing system** deployed in a major Latin American city. **Describe how historical bias present in the training data** (e.g., police reporting practices) could cause the system to disproportionately target and surveil marginalized communities, resulting in discriminatory legal effects (a violation of LOPDP's principle of proportionality and the right to object to automated decisions).\n",
        "\n",
        "* **Explain the security threat known as \"Model Memorization\" or \"Data Leakage\" in generative AI.** If an AI chatbot (used internally by a hospital) accidentally memorizes and reveals unmasked patient health information (PHI) shared during a training prompt, what specific privacy right under the LOPDP would be violated?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6AaoHWOeYQlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Solución:**\n",
        "\n",
        "## **Sesgo histórico y discriminación en la vigilancia predictiva:**\n",
        "\n",
        "El despliegue de un sistema de vigilancia predictiva policial en una ciudad latinoamericana representa un escenario de alto riesgo donde el **sesgo histórico** en los datos puede generar daños severos. Si el sistema se entrena con registros históricos de arrestos que reflejan prácticas policiales discriminatorias (por ejemplo, mayor patrullaje en barrios marginales), el algoritmo aprenderá a asociar la criminalidad con ubicaciones o demografías específicas, creando un **ciclo de retroalimentación negativa**. Esto resultaría en una vigilancia desproporcionada sobre comunidades vulnerables, violando directamente el **principio de proporcionalidad** de la LOPDP, ya que el tratamiento de datos se vuelve excesivo e inadecuado para el fin de la seguridad pública justa. El algoritmo, en esencia, no estaría prediciendo el crimen, sino prediciendo la presencia policial basada en prejuicios codificados, lo que vulnera el derecho del ciudadano a no ser objeto de decisiones automatizadas discriminatorias.\n",
        "\n",
        "## **Definición de memorización y fuga de datos en IA Generativa:**\n",
        "\n",
        "La amenaza de **\"Memorización del Modelo\"** (*Model Memorization*) ocurre cuando un modelo de lenguaje profundo (LLM) sobreajusta sus datos de entrenamiento hasta el punto de poder **reproducir secuencias exactas** de la información original, en lugar de aprender solo patrones generales. Este fenómeno conduce a la **\"Fuga de Datos\"** (*Data Leakage*), donde el modelo expone información sensible contenida en su *set* de entrenamiento al ser consultado con ciertos *prompts*. Esta fuga representa un grave riesgo de seguridad y privacidad, especialmente cuando se procesan datos confidenciales en entornos internos.\n",
        "\n",
        "## **Violación específica a la LOPDP por fuga de datos de salud (PHI):**\n",
        "\n",
        "Si un *chatbot* utilizado internamente por un hospital memorizara y revelara accidentalmente **Información de Salud no anonimizada (PHI)** de un paciente durante una interacción, se violaría gravemente el régimen de protección de **Categorías Especiales de Datos (Datos Sensibles)**, estipulado en los Artículos 25 y 26 de la LOPDP. Específicamente, se vulneraría el **principio de confidencialidad** (Artículo 10.g) y el **deber de seguridad** que exige al responsable del tratamiento proteger la integridad y el acceso no autorizado a los datos. Esta falla técnica expone al hospital a sanciones severas por no haber implementado medidas de mitigación adecuadas, como la anonimización robusta o filtros de salida, para impedir la reidentificación de pacientes."
      ],
      "metadata": {
        "id": "XMEnjyX2YejJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **Referencias Bibliográficas:**\n",
        "\n",
        "1.  Asamblea Nacional del Ecuador. (2021). *Ley Orgánica de Protección de Datos Personales.* Registro Oficial Suplemento 459.\n",
        "2.  AVL Abogados. (2025). *Normativa para la transferencia nacional e internacional de datos personales.* AVL Legal.\n",
        "3.  ComplexDiscovery. (2024). *Controversy Erupts Over LinkedIn's AI Data Usage Policies.* ComplexDiscovery OÜ.\n",
        "4.  IBM Research. (2023). *What is generative AI?*. IBM.\n",
        "5.  Maginative. (2024). *Brazil Blocks Meta from Using Local Data to Train AI Models.* Maginative.\n",
        "6.  OpenAI. (2024). *Enterprise privacy at OpenAI.* OpenAI Platform.\n",
        "7.  Procuraduría Universitaria UTPL. (2021). *Ley Orgánica de Protección de Datos Personales: Concordancias y Análisis.* Universidad Técnica Particular de Loja."
      ],
      "metadata": {
        "id": "iLT7qyxZZCsD"
      }
    }
  ]
}